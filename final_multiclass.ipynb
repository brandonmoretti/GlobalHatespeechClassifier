{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate\n",
    "#!pip install tensorflow\n",
    "#!pip install tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:10:10.986063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-28 16:10:11.013267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745871011.044929  117425 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745871011.054159  117425 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745871011.077610  117425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745871011.077654  117425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745871011.077658  117425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745871011.077660  117425 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-28 16:10:11.088151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib \n",
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berkeley Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>target_race_asian</th>\n",
       "      <th>target_race_black</th>\n",
       "      <th>target_race_latinx</th>\n",
       "      <th>target_race_middle_eastern</th>\n",
       "      <th>target_race_native_american</th>\n",
       "      <th>target_race_pacific_islander</th>\n",
       "      <th>target_race_white</th>\n",
       "      <th>target_religion_atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>target_sexuality_lesbian</th>\n",
       "      <th>target_sexuality_straight</th>\n",
       "      <th>target_sexuality_other</th>\n",
       "      <th>target_disability_physical</th>\n",
       "      <th>target_disability_cognitive</th>\n",
       "      <th>target_disability_neurological</th>\n",
       "      <th>target_disability_visually_impaired</th>\n",
       "      <th>target_disability_hearing_impaired</th>\n",
       "      <th>target_disability_unspecific</th>\n",
       "      <th>target_disability_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hatespeech                                               text  \\\n",
       "0         0.0  Yes indeed. She sort of reminds me of the elde...   \n",
       "1         0.0  The trans women reading this tweet right now i...   \n",
       "2         2.0  Question: These 4 broads who criticize America...   \n",
       "3         0.0  It is about time for all illegals to go back t...   \n",
       "4         2.0  For starters bend over the one in pink and kic...   \n",
       "\n",
       "   target_race_asian  target_race_black  target_race_latinx  \\\n",
       "0               True               True                True   \n",
       "1              False              False               False   \n",
       "2              False              False               False   \n",
       "3              False              False               False   \n",
       "4              False              False               False   \n",
       "\n",
       "   target_race_middle_eastern  target_race_native_american  \\\n",
       "0                        True                         True   \n",
       "1                       False                        False   \n",
       "2                       False                        False   \n",
       "3                       False                        False   \n",
       "4                       False                        False   \n",
       "\n",
       "   target_race_pacific_islander  target_race_white  target_religion_atheist  \\\n",
       "0                          True               True                    False   \n",
       "1                         False              False                    False   \n",
       "2                         False              False                    False   \n",
       "3                         False              False                    False   \n",
       "4                         False              False                    False   \n",
       "\n",
       "   ...  target_sexuality_lesbian  target_sexuality_straight  \\\n",
       "0  ...                     False                      False   \n",
       "1  ...                     False                      False   \n",
       "2  ...                     False                      False   \n",
       "3  ...                     False                      False   \n",
       "4  ...                     False                      False   \n",
       "\n",
       "   target_sexuality_other  target_disability_physical  \\\n",
       "0                   False                       False   \n",
       "1                   False                       False   \n",
       "2                   False                       False   \n",
       "3                   False                       False   \n",
       "4                   False                       False   \n",
       "\n",
       "   target_disability_cognitive  target_disability_neurological  \\\n",
       "0                        False                           False   \n",
       "1                        False                           False   \n",
       "2                        False                           False   \n",
       "3                        False                           False   \n",
       "4                        False                           False   \n",
       "\n",
       "   target_disability_visually_impaired  target_disability_hearing_impaired  \\\n",
       "0                                False                               False   \n",
       "1                                False                               False   \n",
       "2                                False                               False   \n",
       "3                                False                               False   \n",
       "4                                False                               False   \n",
       "\n",
       "   target_disability_unspecific  target_disability_other  \n",
       "0                         False                    False  \n",
       "1                         False                    False  \n",
       "2                         False                    False  \n",
       "3                         False                    False  \n",
       "4                         False                    False  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "berkeley = pd.read_parquet(\"hf://datasets/ucberkeley-dlab/measuring-hate-speech/measuring-hate-speech.parquet\")\n",
    "\n",
    "columns_relevant =  ['hatespeech', 'text', 'target_race_asian', 'target_race_black', 'target_race_latinx', 'target_race_middle_eastern',\n",
    "'target_race_native_american', 'target_race_pacific_islander', 'target_race_white', 'target_religion_atheist', 'target_religion_buddhist',\n",
    "'target_religion_christian', 'target_religion_hindu', 'target_religion_jewish', 'target_religion_mormon', 'target_religion_muslim', \n",
    "'target_religion_other', 'target_origin_immigrant', 'target_origin_migrant_worker', 'target_origin_undocumented', \n",
    "'target_gender_men', 'target_gender_non_binary', 'target_gender_transgender_men', 'target_gender_transgender_unspecified',\n",
    "'target_gender_transgender_women', 'target_gender_women', 'target_sexuality_bisexual', 'target_sexuality_gay', 'target_sexuality_lesbian',\n",
    "'target_sexuality_straight', 'target_sexuality_other', 'target_disability_physical', 'target_disability_cognitive',\n",
    "'target_disability_neurological', 'target_disability_visually_impaired', 'target_disability_hearing_impaired', 'target_disability_unspecific',\n",
    "'target_disability_other']\n",
    "\n",
    "berkeley_columns_relevant = berkeley[columns_relevant]\n",
    "berkeley_columns_relevant.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove non-hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>target_race_asian</th>\n",
       "      <th>target_race_black</th>\n",
       "      <th>target_race_latinx</th>\n",
       "      <th>target_race_middle_eastern</th>\n",
       "      <th>target_race_native_american</th>\n",
       "      <th>target_race_pacific_islander</th>\n",
       "      <th>target_race_white</th>\n",
       "      <th>target_religion_atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>target_sexuality_lesbian</th>\n",
       "      <th>target_sexuality_straight</th>\n",
       "      <th>target_sexuality_other</th>\n",
       "      <th>target_disability_physical</th>\n",
       "      <th>target_disability_cognitive</th>\n",
       "      <th>target_disability_neurological</th>\n",
       "      <th>target_disability_visually_impaired</th>\n",
       "      <th>target_disability_hearing_impaired</th>\n",
       "      <th>target_disability_unspecific</th>\n",
       "      <th>target_disability_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135546</th>\n",
       "      <td>1.0</td>\n",
       "      <td>🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 &lt;Round8&gt; 1...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135547</th>\n",
       "      <td>1.0</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1.0</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>2.0</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54932 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  \\\n",
       "2              2.0  Question: These 4 broads who criticize America...   \n",
       "4              2.0  For starters bend over the one in pink and kic...   \n",
       "6              2.0  Who the fuck is this insignificant simple mind...   \n",
       "7              2.0         Fuck off you insufferable retarded faggot.   \n",
       "9              2.0  Worthless whore, these tits with look nice wit...   \n",
       "...            ...                                                ...   \n",
       "135523         1.0  Lady in the back Blinks when \"her\" camera red ...   \n",
       "135546         1.0  🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 <Round8> 1...   \n",
       "135547         1.0  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...   \n",
       "135548         1.0  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...   \n",
       "135555         2.0  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...   \n",
       "\n",
       "        target_race_asian  target_race_black  target_race_latinx  \\\n",
       "2                   False              False               False   \n",
       "4                   False              False               False   \n",
       "6                   False              False               False   \n",
       "7                   False              False               False   \n",
       "9                   False              False               False   \n",
       "...                   ...                ...                 ...   \n",
       "135523              False              False               False   \n",
       "135546              False              False               False   \n",
       "135547              False              False               False   \n",
       "135548              False              False               False   \n",
       "135555              False              False               False   \n",
       "\n",
       "        target_race_middle_eastern  target_race_native_american  \\\n",
       "2                            False                        False   \n",
       "4                            False                        False   \n",
       "6                            False                        False   \n",
       "7                            False                        False   \n",
       "9                            False                        False   \n",
       "...                            ...                          ...   \n",
       "135523                       False                        False   \n",
       "135546                       False                        False   \n",
       "135547                       False                        False   \n",
       "135548                        True                        False   \n",
       "135555                       False                        False   \n",
       "\n",
       "        target_race_pacific_islander  target_race_white  \\\n",
       "2                              False              False   \n",
       "4                              False              False   \n",
       "6                              False               True   \n",
       "7                              False              False   \n",
       "9                              False              False   \n",
       "...                              ...                ...   \n",
       "135523                         False              False   \n",
       "135546                         False              False   \n",
       "135547                         False              False   \n",
       "135548                         False              False   \n",
       "135555                         False              False   \n",
       "\n",
       "        target_religion_atheist  ...  target_sexuality_lesbian  \\\n",
       "2                         False  ...                     False   \n",
       "4                         False  ...                     False   \n",
       "6                         False  ...                     False   \n",
       "7                         False  ...                     False   \n",
       "9                         False  ...                     False   \n",
       "...                         ...  ...                       ...   \n",
       "135523                    False  ...                     False   \n",
       "135546                    False  ...                     False   \n",
       "135547                    False  ...                     False   \n",
       "135548                    False  ...                     False   \n",
       "135555                    False  ...                     False   \n",
       "\n",
       "        target_sexuality_straight  target_sexuality_other  \\\n",
       "2                           False                   False   \n",
       "4                           False                   False   \n",
       "6                           False                   False   \n",
       "7                           False                   False   \n",
       "9                           False                   False   \n",
       "...                           ...                     ...   \n",
       "135523                      False                    True   \n",
       "135546                      False                   False   \n",
       "135547                      False                   False   \n",
       "135548                      False                   False   \n",
       "135555                      False                   False   \n",
       "\n",
       "        target_disability_physical  target_disability_cognitive  \\\n",
       "2                            False                        False   \n",
       "4                            False                        False   \n",
       "6                            False                        False   \n",
       "7                            False                        False   \n",
       "9                            False                        False   \n",
       "...                            ...                          ...   \n",
       "135523                       False                        False   \n",
       "135546                       False                        False   \n",
       "135547                       False                        False   \n",
       "135548                       False                        False   \n",
       "135555                       False                        False   \n",
       "\n",
       "        target_disability_neurological  target_disability_visually_impaired  \\\n",
       "2                                False                                False   \n",
       "4                                False                                False   \n",
       "6                                False                                False   \n",
       "7                                False                                False   \n",
       "9                                False                                False   \n",
       "...                                ...                                  ...   \n",
       "135523                           False                                False   \n",
       "135546                           False                                False   \n",
       "135547                           False                                False   \n",
       "135548                           False                                False   \n",
       "135555                           False                                False   \n",
       "\n",
       "        target_disability_hearing_impaired  target_disability_unspecific  \\\n",
       "2                                    False                         False   \n",
       "4                                    False                         False   \n",
       "6                                    False                         False   \n",
       "7                                    False                         False   \n",
       "9                                    False                         False   \n",
       "...                                    ...                           ...   \n",
       "135523                               False                         False   \n",
       "135546                               False                         False   \n",
       "135547                               False                         False   \n",
       "135548                               False                         False   \n",
       "135555                               False                         False   \n",
       "\n",
       "        target_disability_other  \n",
       "2                         False  \n",
       "4                         False  \n",
       "6                         False  \n",
       "7                         False  \n",
       "9                         False  \n",
       "...                         ...  \n",
       "135523                    False  \n",
       "135546                    False  \n",
       "135547                    False  \n",
       "135548                    False  \n",
       "135555                    False  \n",
       "\n",
       "[54932 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berkely_hate = berkeley_columns_relevant[berkeley_columns_relevant['hatespeech'] > 0]\n",
    "berkely_hate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14097/ipykernel_117425/2584169070.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  berkely_hate.loc[:, 'Transgender'] = berkely_hate[t_cols].any(axis=1)\n",
      "/scratch/slurm-14097/ipykernel_117425/2584169070.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  berkely_hate.loc[:, 'LGB+'] = berkely_hate[lgb_cols].any(axis=1)\n",
      "/scratch/slurm-14097/ipykernel_117425/2584169070.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  berkely_hate.loc[:, 'Disabled'] = berkely_hate[disability_cols].any(axis=1)\n",
      "/scratch/slurm-14097/ipykernel_117425/2584169070.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  berkely_hate.loc[:, 'Immigrant'] = berkely_hate[immigrant_cols].any(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>Native American</th>\n",
       "      <th>Pacific Islander</th>\n",
       "      <th>White</th>\n",
       "      <th>Atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Other Religion</th>\n",
       "      <th>Men</th>\n",
       "      <th>Non-Binary</th>\n",
       "      <th>Women</th>\n",
       "      <th>Straight</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135546</th>\n",
       "      <td>1</td>\n",
       "      <td>🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 &lt;Round8&gt; 1...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135547</th>\n",
       "      <td>1</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>1</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54932 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  Asian  \\\n",
       "2                1  Question: These 4 broads who criticize America...  False   \n",
       "4                1  For starters bend over the one in pink and kic...  False   \n",
       "6                1  Who the fuck is this insignificant simple mind...  False   \n",
       "7                1         Fuck off you insufferable retarded faggot.  False   \n",
       "9                1  Worthless whore, these tits with look nice wit...  False   \n",
       "...            ...                                                ...    ...   \n",
       "135523           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135546           1  🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 <Round8> 1...  False   \n",
       "135547           1  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...  False   \n",
       "135548           1  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...  False   \n",
       "135555           1  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...  False   \n",
       "\n",
       "        Black  Latinx  Middle Eastern  Native American  Pacific Islander  \\\n",
       "2       False   False           False            False             False   \n",
       "4       False   False           False            False             False   \n",
       "6       False   False           False            False             False   \n",
       "7       False   False           False            False             False   \n",
       "9       False   False           False            False             False   \n",
       "...       ...     ...             ...              ...               ...   \n",
       "135523  False   False           False            False             False   \n",
       "135546  False   False           False            False             False   \n",
       "135547  False   False           False            False             False   \n",
       "135548  False   False            True            False             False   \n",
       "135555  False   False           False            False             False   \n",
       "\n",
       "        White  Atheist  ...  Muslim  Other Religion    Men  Non-Binary  Women  \\\n",
       "2       False    False  ...   False           False  False       False  False   \n",
       "4       False    False  ...   False           False  False       False   True   \n",
       "6        True    False  ...   False           False  False       False  False   \n",
       "7       False    False  ...   False           False  False       False  False   \n",
       "9       False    False  ...   False           False  False       False   True   \n",
       "...       ...      ...  ...     ...             ...    ...         ...    ...   \n",
       "135523  False    False  ...   False           False  False       False  False   \n",
       "135546  False    False  ...   False           False  False       False  False   \n",
       "135547  False    False  ...   False           False  False       False  False   \n",
       "135548  False    False  ...   False           False  False       False  False   \n",
       "135555  False    False  ...   False           False  False       False  False   \n",
       "\n",
       "        Straight  Transgender   LGB+  Disabled  Immigrant  \n",
       "2          False        False  False     False       True  \n",
       "4          False        False  False     False      False  \n",
       "6          False        False  False     False      False  \n",
       "7          False        False   True     False      False  \n",
       "9          False        False  False     False      False  \n",
       "...          ...          ...    ...       ...        ...  \n",
       "135523     False        False   True     False      False  \n",
       "135546     False        False  False     False      False  \n",
       "135547     False        False  False     False      False  \n",
       "135548     False        False  False     False      False  \n",
       "135555     False        False  False     False      False  \n",
       "\n",
       "[54932 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_cols = [ 'target_sexuality_bisexual', 'target_sexuality_gay', 'target_sexuality_lesbian', 'target_sexuality_other']\n",
    "\n",
    "t_cols = ['target_gender_transgender_men', 'target_gender_transgender_unspecified','target_gender_transgender_women']\n",
    "\n",
    "disability_cols = ['target_disability_physical', 'target_disability_cognitive', 'target_disability_neurological',\n",
    "'target_disability_visually_impaired', 'target_disability_hearing_impaired', 'target_disability_unspecific', 'target_disability_other']\n",
    "\n",
    "immigrant_cols = ['target_origin_immigrant', 'target_origin_migrant_worker', 'target_origin_undocumented']\n",
    "\n",
    "\n",
    "berkely_hate.loc[:, 'Transgender'] = berkely_hate[t_cols].any(axis=1)\n",
    "berkely_hate.loc[:, 'LGB+'] = berkely_hate[lgb_cols].any(axis=1)\n",
    "berkely_hate.loc[:, 'Disabled'] = berkely_hate[disability_cols].any(axis=1)\n",
    "berkely_hate.loc[:, 'Immigrant'] = berkely_hate[immigrant_cols].any(axis=1)\n",
    "\n",
    "\n",
    "berkely_hate = berkely_hate.copy()\n",
    "berkely_hate.rename(columns={'target_race_asian': 'Asian', 'target_race_black': 'Black', 'target_race_latinx': 'Latinx', \n",
    "'target_race_middle_eastern': 'Middle Eastern', 'target_race_pacific_islander': 'Pacific Islander', 'target_race_white': 'White', \n",
    "'target_religion_atheist': 'Atheist', 'target_religion_buddhist': 'Buddhist', 'target_religion_christian':'Christian','target_religion_hindu': 'Hindu', \n",
    "'target_religion_jewish': 'Jewish','target_religion_mormon': 'Mormon',\n",
    "'target_religion_muslim': 'Muslim', 'target_religion_other': 'Other Religion', 'target_gender_men': 'Men', \n",
    "'target_gender_non_binary': 'Non-Binary', 'target_gender_women': 'Women', 'target_sexuality_straight': 'Straight', 'target_race_native_american': 'Native American',\n",
    "}, inplace=True)\n",
    "\n",
    "berkeley_compressed = berkely_hate.drop(lgb_cols + t_cols + disability_cols + immigrant_cols, axis=1)\n",
    "\n",
    "berkeley_compressed['hatespeech'] = berkeley_compressed['hatespeech'].apply(lambda x: 1 if x > 0 else 0)\n",
    "berkeley_compressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>Native American</th>\n",
       "      <th>Pacific Islander</th>\n",
       "      <th>White</th>\n",
       "      <th>Atheist</th>\n",
       "      <th>Buddhist</th>\n",
       "      <th>Christian</th>\n",
       "      <th>...</th>\n",
       "      <th>Mormon</th>\n",
       "      <th>Other Religion</th>\n",
       "      <th>Men</th>\n",
       "      <th>Non-Binary</th>\n",
       "      <th>Women</th>\n",
       "      <th>Straight</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nonhate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hate</th>\n",
       "      <td>3651</td>\n",
       "      <td>13699</td>\n",
       "      <td>4370</td>\n",
       "      <td>4464</td>\n",
       "      <td>679</td>\n",
       "      <td>696</td>\n",
       "      <td>3692</td>\n",
       "      <td>254</td>\n",
       "      <td>202</td>\n",
       "      <td>1173</td>\n",
       "      <td>...</td>\n",
       "      <td>237</td>\n",
       "      <td>599</td>\n",
       "      <td>3038</td>\n",
       "      <td>484</td>\n",
       "      <td>10693</td>\n",
       "      <td>1484</td>\n",
       "      <td>7804</td>\n",
       "      <td>1497</td>\n",
       "      <td>2365</td>\n",
       "      <td>5586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Asian  Black Latinx Middle Eastern Native American Pacific Islander  \\\n",
       "Nonhate     0      0      0              0               0                0   \n",
       "Hate     3651  13699   4370           4464             679              696   \n",
       "\n",
       "        White Atheist Buddhist Christian  ... Mormon Other Religion   Men  \\\n",
       "Nonhate     0       0        0         0  ...      0              0     0   \n",
       "Hate     3692     254      202      1173  ...    237            599  3038   \n",
       "\n",
       "        Non-Binary  Women Straight  LGB+ Transgender Disabled Immigrant  \n",
       "Nonhate          0      0        0     0           0        0         0  \n",
       "Hate           484  10693     1484  7804        1497     2365      5586  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns_to_sum = ['Asian', 'Black', 'Latinx', 'Middle Eastern', 'Native American', 'Pacific Islander', 'White', 'Atheist', 'Buddhist', 'Christian','Hindu', 'Jewish', 'Muslim', 'Mormon', 'Other Religion', 'Men', 'Non-Binary', 'Women', 'Straight', 'LGB+','Transgender', 'Disabled', 'Immigrant']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hate_counts = berkeley_compressed[columns_to_sum].where(berkeley_compressed['hatespeech'] == 1).sum().to_frame().T\n",
    "nonhate_counts = berkeley_compressed[columns_to_sum].where(berkeley_compressed['hatespeech'] == 0).sum().to_frame().T\n",
    "\n",
    "target_counts = pd.concat([nonhate_counts, hate_counts], ignore_index=True)\n",
    "target_counts.index = ['Nonhate', 'Hate']\n",
    "\n",
    "\n",
    "target_counts.T.plot.bar(stacked=True)\n",
    "target_counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi_lable to multiclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing low-frequency identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>White</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Jewish</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135546</th>\n",
       "      <td>1</td>\n",
       "      <td>🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 &lt;Round8&gt; 1...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135547</th>\n",
       "      <td>1</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>1</td>\n",
       "      <td>لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54932 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  Asian  \\\n",
       "2                1  Question: These 4 broads who criticize America...  False   \n",
       "4                1  For starters bend over the one in pink and kic...  False   \n",
       "6                1  Who the fuck is this insignificant simple mind...  False   \n",
       "7                1         Fuck off you insufferable retarded faggot.  False   \n",
       "9                1  Worthless whore, these tits with look nice wit...  False   \n",
       "...            ...                                                ...    ...   \n",
       "135523           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135546           1  🔥PUBG JAPAN SERIES 🔥Grade2 Day2 6/7 <Round8> 1...  False   \n",
       "135547           1  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...  False   \n",
       "135548           1  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...  False   \n",
       "135555           1  لا تتشمت الرجال مسكين يعاني كس امه 😂. يقول يال...  False   \n",
       "\n",
       "        Black  Latinx  Middle Eastern  White  Christian  Jewish  Muslim  \\\n",
       "2       False   False           False  False      False   False   False   \n",
       "4       False   False           False  False      False   False   False   \n",
       "6       False   False           False   True      False   False   False   \n",
       "7       False   False           False  False      False   False   False   \n",
       "9       False   False           False  False      False   False   False   \n",
       "...       ...     ...             ...    ...        ...     ...     ...   \n",
       "135523  False   False           False  False      False   False   False   \n",
       "135546  False   False           False  False      False   False   False   \n",
       "135547  False   False           False  False      False   False   False   \n",
       "135548  False   False            True  False      False   False   False   \n",
       "135555  False   False           False  False      False   False   False   \n",
       "\n",
       "          Men  Women  Transgender   LGB+  Disabled  Immigrant  \n",
       "2       False  False        False  False     False       True  \n",
       "4       False   True        False  False     False      False  \n",
       "6       False  False        False  False     False      False  \n",
       "7       False  False        False   True     False      False  \n",
       "9       False   True        False  False     False      False  \n",
       "...       ...    ...          ...    ...       ...        ...  \n",
       "135523  False  False        False   True     False      False  \n",
       "135546  False  False        False  False     False      False  \n",
       "135547  False  False        False  False     False      False  \n",
       "135548  False  False        False  False     False      False  \n",
       "135555  False  False        False  False     False      False  \n",
       "\n",
       "[54932 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing native american, pacific islander, athiest, buddhist,  hindu, mormon, other religions, non-binary\n",
    "high_frequency_targets = berkeley_compressed.drop(['Native American', 'Pacific Islander', 'Atheist', 'Buddhist', \n",
    "                                                     'Hindu', 'Mormon', 'Other Religion', 'Non-Binary', 'Straight'], axis = 1)\n",
    "high_frequency_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14097/ipykernel_117425/868952246.py:9: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  berkely_dropped_multi = berkely_dropped_none[~multi_identities]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>White</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Jewish</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135406</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135435</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135515</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38605 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  Asian  \\\n",
       "2                1  Question: These 4 broads who criticize America...  False   \n",
       "4                1  For starters bend over the one in pink and kic...  False   \n",
       "6                1  Who the fuck is this insignificant simple mind...  False   \n",
       "7                1         Fuck off you insufferable retarded faggot.  False   \n",
       "9                1  Worthless whore, these tits with look nice wit...  False   \n",
       "...            ...                                                ...    ...   \n",
       "135406           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135435           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135515           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135523           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135548           1  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...  False   \n",
       "\n",
       "        Black  Latinx  Middle Eastern  White  Christian  Jewish  Muslim  \\\n",
       "2       False   False           False  False      False   False   False   \n",
       "4       False   False           False  False      False   False   False   \n",
       "6       False   False           False   True      False   False   False   \n",
       "7       False   False           False  False      False   False   False   \n",
       "9       False   False           False  False      False   False   False   \n",
       "...       ...     ...             ...    ...        ...     ...     ...   \n",
       "135406  False   False           False  False      False   False   False   \n",
       "135435  False   False           False  False      False   False   False   \n",
       "135515  False   False           False  False      False   False   False   \n",
       "135523  False   False           False  False      False   False   False   \n",
       "135548  False   False            True  False      False   False   False   \n",
       "\n",
       "          Men  Women  Transgender   LGB+  Disabled  Immigrant  \n",
       "2       False  False        False  False     False       True  \n",
       "4       False   True        False  False     False      False  \n",
       "6       False  False        False  False     False      False  \n",
       "7       False  False        False   True     False      False  \n",
       "9       False   True        False  False     False      False  \n",
       "...       ...    ...          ...    ...       ...        ...  \n",
       "135406  False  False        False   True     False      False  \n",
       "135435  False  False         True  False     False      False  \n",
       "135515  False  False         True  False     False      False  \n",
       "135523  False  False        False   True     False      False  \n",
       "135548  False  False        False  False     False      False  \n",
       "\n",
       "[38605 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_identities = high_frequency_targets.loc[:,\"Asian\":\"Immigrant\"].sum(axis = 1)\n",
    "#print(num_identities)\n",
    "num_identities\n",
    "\n",
    "multi_identities = num_identities > 1\n",
    "no_identities = num_identities == 0\n",
    "\n",
    "berkely_dropped_none =high_frequency_targets[~no_identities]\n",
    "berkely_dropped_multi = berkely_dropped_none[~multi_identities]\n",
    "\n",
    "berkely_dropped_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### changing to multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135406</th>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135435</th>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135515</th>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>Middle Eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38605 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      \n",
       "2            Immigrant\n",
       "4                Women\n",
       "6                White\n",
       "7                 LGB+\n",
       "9                Women\n",
       "...                ...\n",
       "135406            LGB+\n",
       "135435     Transgender\n",
       "135515     Transgender\n",
       "135523            LGB+\n",
       "135548  Middle Eastern\n",
       "\n",
       "[38605 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#multi_class_dummy = high_frequency_targets.astype(int)\n",
    "multi_class_column = pd.from_dummies(berkely_dropped_multi.loc[:,'Asian':'Immigrant'])\n",
    "multi_class_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>White</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Jewish</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135406</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135435</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135515</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Middle Eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38605 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  Asian  \\\n",
       "2                1  Question: These 4 broads who criticize America...  False   \n",
       "4                1  For starters bend over the one in pink and kic...  False   \n",
       "6                1  Who the fuck is this insignificant simple mind...  False   \n",
       "7                1         Fuck off you insufferable retarded faggot.  False   \n",
       "9                1  Worthless whore, these tits with look nice wit...  False   \n",
       "...            ...                                                ...    ...   \n",
       "135406           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135435           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135515           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135523           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135548           1  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...  False   \n",
       "\n",
       "        Black  Latinx  Middle Eastern  White  Christian  Jewish  Muslim  \\\n",
       "2       False   False           False  False      False   False   False   \n",
       "4       False   False           False  False      False   False   False   \n",
       "6       False   False           False   True      False   False   False   \n",
       "7       False   False           False  False      False   False   False   \n",
       "9       False   False           False  False      False   False   False   \n",
       "...       ...     ...             ...    ...        ...     ...     ...   \n",
       "135406  False   False           False  False      False   False   False   \n",
       "135435  False   False           False  False      False   False   False   \n",
       "135515  False   False           False  False      False   False   False   \n",
       "135523  False   False           False  False      False   False   False   \n",
       "135548  False   False            True  False      False   False   False   \n",
       "\n",
       "          Men  Women  Transgender   LGB+  Disabled  Immigrant                  \n",
       "2       False  False        False  False     False       True       Immigrant  \n",
       "4       False   True        False  False     False      False           Women  \n",
       "6       False  False        False  False     False      False           White  \n",
       "7       False  False        False   True     False      False            LGB+  \n",
       "9       False   True        False  False     False      False           Women  \n",
       "...       ...    ...          ...    ...       ...        ...             ...  \n",
       "135406  False  False        False   True     False      False            LGB+  \n",
       "135435  False  False         True  False     False      False     Transgender  \n",
       "135515  False  False         True  False     False      False     Transgender  \n",
       "135523  False  False        False   True     False      False            LGB+  \n",
       "135548  False  False        False  False     False      False  Middle Eastern  \n",
       "\n",
       "[38605 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class = pd.concat([berkely_dropped_multi,multi_class_column], axis = 1)\n",
    "multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hatespeech</th>\n",
       "      <th>text</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Latinx</th>\n",
       "      <th>Middle Eastern</th>\n",
       "      <th>White</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Jewish</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Transgender</th>\n",
       "      <th>LGB+</th>\n",
       "      <th>Disabled</th>\n",
       "      <th>Immigrant</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Immigrant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Who the fuck is this insignificant simple mind...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>Fuck off you insufferable retarded faggot.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Worthless whore, these tits with look nice wit...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135406</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135435</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135515</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Transgender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135523</th>\n",
       "      <td>1</td>\n",
       "      <td>Lady in the back Blinks when \"her\" camera red ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>LGB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>1</td>\n",
       "      <td>#DSSUpliftsTheThirdGender #EmancipationOfEunuc...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Middle Eastern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38605 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hatespeech                                               text  Asian  \\\n",
       "2                1  Question: These 4 broads who criticize America...  False   \n",
       "4                1  For starters bend over the one in pink and kic...  False   \n",
       "6                1  Who the fuck is this insignificant simple mind...  False   \n",
       "7                1         Fuck off you insufferable retarded faggot.  False   \n",
       "9                1  Worthless whore, these tits with look nice wit...  False   \n",
       "...            ...                                                ...    ...   \n",
       "135406           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135435           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135515           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135523           1  Lady in the back Blinks when \"her\" camera red ...  False   \n",
       "135548           1  #DSSUpliftsTheThirdGender #EmancipationOfEunuc...  False   \n",
       "\n",
       "        Black  Latinx  Middle Eastern  White  Christian  Jewish  Muslim  \\\n",
       "2       False   False           False  False      False   False   False   \n",
       "4       False   False           False  False      False   False   False   \n",
       "6       False   False           False   True      False   False   False   \n",
       "7       False   False           False  False      False   False   False   \n",
       "9       False   False           False  False      False   False   False   \n",
       "...       ...     ...             ...    ...        ...     ...     ...   \n",
       "135406  False   False           False  False      False   False   False   \n",
       "135435  False   False           False  False      False   False   False   \n",
       "135515  False   False           False  False      False   False   False   \n",
       "135523  False   False           False  False      False   False   False   \n",
       "135548  False   False            True  False      False   False   False   \n",
       "\n",
       "          Men  Women  Transgender   LGB+  Disabled  Immigrant           label  \n",
       "2       False  False        False  False     False       True       Immigrant  \n",
       "4       False   True        False  False     False      False           Women  \n",
       "6       False  False        False  False     False      False           White  \n",
       "7       False  False        False   True     False      False            LGB+  \n",
       "9       False   True        False  False     False      False           Women  \n",
       "...       ...    ...          ...    ...       ...        ...             ...  \n",
       "135406  False  False        False   True     False      False            LGB+  \n",
       "135435  False  False         True  False     False      False     Transgender  \n",
       "135515  False  False         True  False     False      False     Transgender  \n",
       "135523  False  False        False   True     False      False            LGB+  \n",
       "135548  False  False        False  False     False      False  Middle Eastern  \n",
       "\n",
       "[38605 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_class.columns.values[16] = \"label\"\n",
    "\n",
    "multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hatespeech                                                        1\n",
       "text              Get rid of them and their anchor babies and gr...\n",
       "Asian                                                         False\n",
       "Black                                                         False\n",
       "Latinx                                                        False\n",
       "Middle Eastern                                                False\n",
       "White                                                         False\n",
       "Christian                                                     False\n",
       "Jewish                                                        False\n",
       "Muslim                                                        False\n",
       "Men                                                           False\n",
       "Women                                                         False\n",
       "Transgender                                                   False\n",
       "LGB+                                                          False\n",
       "Disabled                                                      False\n",
       "Immigrant                                                     False\n",
       "Name: 24, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berkely_dropped_multi.iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arabic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>الوزير جبران باسيل تاج راسك يا جربان ممنوع بعد...</td>\n",
       "      <td>abusive</td>\n",
       "      <td>Minister Gebran Bassil, crown your head, O Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>صديقي انت ابن جامعه اللعبه اكبر من داعش اللعبه...</td>\n",
       "      <td>normal</td>\n",
       "      <td>My friend, you are a university student. The g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>و مصلحة لبنان تبدأ باستخراج النفط و الغاز لوقف...</td>\n",
       "      <td>normal</td>\n",
       "      <td>Lebanon’s interest begins with extracting oil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>وليد جنبلاط كاتب الحكمة يا قذر</td>\n",
       "      <td>abusive</td>\n",
       "      <td>Walid Jumblatt, writer of wisdom, filthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>شو بتلبقلك كلمة خنزير بتجي مفصله على قياسك وشكلك</td>\n",
       "      <td>abusive</td>\n",
       "      <td>What do you think about the word “pig” that is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>أمير المليشيا مش خائن</td>\n",
       "      <td>normal</td>\n",
       "      <td>The militia prince is not a traitor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5842</th>\n",
       "      <td>صدقت يناسبك جدا جدا</td>\n",
       "      <td>normal</td>\n",
       "      <td>You are right, it suits you very well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>لبخليني حب باسيل شغلتين</td>\n",
       "      <td>normal</td>\n",
       "      <td>Basil's love leaves me with two things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5844</th>\n",
       "      <td>ليش تيوس الإمارت والسعودية مع السوريين واليمني...</td>\n",
       "      <td>hate</td>\n",
       "      <td>Why are the goats of the Emirates and Saudi Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5845</th>\n",
       "      <td>مش دفاعاً عن جبران باسيل بس كان لازم تحط المقط...</td>\n",
       "      <td>normal</td>\n",
       "      <td>Not in defense of Gebran Bassil, but you shoul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5846 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet    Class  \\\n",
       "0     الوزير جبران باسيل تاج راسك يا جربان ممنوع بعد...  abusive   \n",
       "1     صديقي انت ابن جامعه اللعبه اكبر من داعش اللعبه...   normal   \n",
       "2     و مصلحة لبنان تبدأ باستخراج النفط و الغاز لوقف...   normal   \n",
       "3                        وليد جنبلاط كاتب الحكمة يا قذر  abusive   \n",
       "4      شو بتلبقلك كلمة خنزير بتجي مفصله على قياسك وشكلك  abusive   \n",
       "...                                                 ...      ...   \n",
       "5841                              أمير المليشيا مش خائن   normal   \n",
       "5842                                صدقت يناسبك جدا جدا   normal   \n",
       "5843                            لبخليني حب باسيل شغلتين   normal   \n",
       "5844  ليش تيوس الإمارت والسعودية مع السوريين واليمني...     hate   \n",
       "5845  مش دفاعاً عن جبران باسيل بس كان لازم تحط المقط...   normal   \n",
       "\n",
       "                                                english  \n",
       "0     Minister Gebran Bassil, crown your head, O Sco...  \n",
       "1     My friend, you are a university student. The g...  \n",
       "2     Lebanon’s interest begins with extracting oil ...  \n",
       "3              Walid Jumblatt, writer of wisdom, filthy  \n",
       "4     What do you think about the word “pig” that is...  \n",
       "...                                                 ...  \n",
       "5841                The militia prince is not a traitor  \n",
       "5842              You are right, it suits you very well  \n",
       "5843             Basil's love leaves me with two things  \n",
       "5844  Why are the goats of the Emirates and Saudi Ar...  \n",
       "5845  Not in defense of Gebran Bassil, but you shoul...  \n",
       "\n",
       "[5846 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_data = pd.read_csv('levantine_arabic.csv',sep = \",\")\n",
    "arabic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## german data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>english</th>\n",
       "      <th>Reject Newspaper</th>\n",
       "      <th>Reject Crowd</th>\n",
       "      <th>Rejection Count Crowd</th>\n",
       "      <th>Sexism Count Crowd</th>\n",
       "      <th>Racism Count Crowd</th>\n",
       "      <th>Threat Count Crowd</th>\n",
       "      <th>Insult Count Crowd</th>\n",
       "      <th>Profanity Count Crowd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1911223</td>\n",
       "      <td>Niemand braucht Laschet den Merkel Günstling !...</td>\n",
       "      <td>Nobody needs Laschet the Merkel favorite! If s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1911225</td>\n",
       "      <td>das war apokalypse now. nicht einmal zu einem ...</td>\n",
       "      <td>that was apocalypse now. It wasn't even enough...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1911229</td>\n",
       "      <td>Katastrophal  -  Katastrophal -  anders kann d...</td>\n",
       "      <td>Catastrophic - catastrophic - there is NO othe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1911239</td>\n",
       "      <td>Dann sollten wir unsere Rüstungsexporte schnel...</td>\n",
       "      <td>Then we should expand our arms exports quickly...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1911243</td>\n",
       "      <td>na ja,im notfall sind wir amis ja noch da um z...</td>\n",
       "      <td>Well, in an emergency, we Americans are still ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84994</th>\n",
       "      <td>2522729</td>\n",
       "      <td>Mein Gott!! Was für ein entsetzliches Gequatsc...</td>\n",
       "      <td>My God!! What horrible nonsense!!  The lady be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84995</th>\n",
       "      <td>2522757</td>\n",
       "      <td>Der hat halt auch nichts in der hohlen Birne!!!!!</td>\n",
       "      <td>He doesn't have anything in his head either!!!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84996</th>\n",
       "      <td>2522763</td>\n",
       "      <td>Blabla, nehme das Auto...</td>\n",
       "      <td>Blah blah, take the car...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84997</th>\n",
       "      <td>2522959</td>\n",
       "      <td>sack reis in china umgefallen...</td>\n",
       "      <td>Sack of rice fell over in China...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84998</th>\n",
       "      <td>2522997</td>\n",
       "      <td>Na, dann bin ich ja beruhigt, dass Frl. Julia ...</td>\n",
       "      <td>Well, then I'm reassured that Miss Julia belie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84999 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               Text  \\\n",
       "0      1911223  Niemand braucht Laschet den Merkel Günstling !...   \n",
       "1      1911225  das war apokalypse now. nicht einmal zu einem ...   \n",
       "2      1911229  Katastrophal  -  Katastrophal -  anders kann d...   \n",
       "3      1911239  Dann sollten wir unsere Rüstungsexporte schnel...   \n",
       "4      1911243  na ja,im notfall sind wir amis ja noch da um z...   \n",
       "...        ...                                                ...   \n",
       "84994  2522729  Mein Gott!! Was für ein entsetzliches Gequatsc...   \n",
       "84995  2522757  Der hat halt auch nichts in der hohlen Birne!!!!!   \n",
       "84996  2522763                          Blabla, nehme das Auto...   \n",
       "84997  2522959                   sack reis in china umgefallen...   \n",
       "84998  2522997  Na, dann bin ich ja beruhigt, dass Frl. Julia ...   \n",
       "\n",
       "                                                 english  Reject Newspaper  \\\n",
       "0      Nobody needs Laschet the Merkel favorite! If s...                 0   \n",
       "1      that was apocalypse now. It wasn't even enough...                 0   \n",
       "2      Catastrophic - catastrophic - there is NO othe...                 0   \n",
       "3      Then we should expand our arms exports quickly...                 0   \n",
       "4      Well, in an emergency, we Americans are still ...                 0   \n",
       "...                                                  ...               ...   \n",
       "84994  My God!! What horrible nonsense!!  The lady be...                 1   \n",
       "84995   He doesn't have anything in his head either!!!!!                 1   \n",
       "84996                         Blah blah, take the car...                 1   \n",
       "84997                 Sack of rice fell over in China...                 1   \n",
       "84998  Well, then I'm reassured that Miss Julia belie...                 1   \n",
       "\n",
       "       Reject Crowd  Rejection Count Crowd  Sexism Count Crowd  \\\n",
       "0                 0                      0                 NaN   \n",
       "1                 0                      0                 NaN   \n",
       "2                 0                      1                 0.0   \n",
       "3                 0                      0                 NaN   \n",
       "4                 0                      0                 NaN   \n",
       "...             ...                    ...                 ...   \n",
       "84994             0                      2                 2.0   \n",
       "84995             1                      3                 0.0   \n",
       "84996             0                      0                 NaN   \n",
       "84997             0                      0                 NaN   \n",
       "84998             0                      2                 2.0   \n",
       "\n",
       "       Racism Count Crowd  Threat Count Crowd  Insult Count Crowd  \\\n",
       "0                     NaN                 NaN                 NaN   \n",
       "1                     NaN                 NaN                 NaN   \n",
       "2                     0.0                 0.0                 0.0   \n",
       "3                     NaN                 NaN                 NaN   \n",
       "4                     NaN                 NaN                 NaN   \n",
       "...                   ...                 ...                 ...   \n",
       "84994                 0.0                 0.0                 1.0   \n",
       "84995                 0.0                 0.0                 3.0   \n",
       "84996                 NaN                 NaN                 NaN   \n",
       "84997                 NaN                 NaN                 NaN   \n",
       "84998                 0.0                 0.0                 0.0   \n",
       "\n",
       "       Profanity Count Crowd  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2                        1.0  \n",
       "3                        NaN  \n",
       "4                        NaN  \n",
       "...                      ...  \n",
       "84994                    0.0  \n",
       "84995                    0.0  \n",
       "84996                    NaN  \n",
       "84997                    NaN  \n",
       "84998                    0.0  \n",
       "\n",
       "[84999 rows x 11 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german_data = pd.read_csv('german.csv',sep = \",\")\n",
    "german_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## korean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>contain_gender_bias</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...</td>\n",
       "      <td>False</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>(How the current hotel owner feels) Ah 18 I go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>....the representative of Korean beauty...so p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>...Naughty people...People who enjoyed other p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Episodes 1 and 2 were awkward, but after episo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...</td>\n",
       "      <td>True</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "      <td>1. Scratching a person’s face with a fingernai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>힘내세요~ 응원합니다!!</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Cheer up~ I’m rooting for you!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>힘내세요~~삼가 고인의 명복을 빕니다..</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Cheer up~~ I pray that the deceased rest in pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7893</th>\n",
       "      <td>힘내세용 ^^ 항상 응원합니닷 ^^ !</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Cheer up ^^ I will always support you ^^!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7894</th>\n",
       "      <td>힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>Cheer up... I'll answer with acting. I'm 53 ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7895</th>\n",
       "      <td>힘들면 관뒀어야지 그게 현명한거다</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>If it's hard, you should quit. That's wise.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7896 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  contain_gender_bias  \\\n",
       "0     (현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속...                False   \n",
       "1     ....한국적인 미인의 대표적인 분...너무나 곱고아름다운모습...그모습뒤의 슬픔을...                False   \n",
       "2     ...못된 넘들...남의 고통을 즐겼던 넘들..이젠 마땅한 처벌을 받아야지..,그래...                False   \n",
       "3                    1,2화 어설펐는데 3,4화 지나서부터는 갈수록 너무 재밌던데                False   \n",
       "4     1. 사람 얼굴 손톱으로 긁은것은 인격살해이고2. 동영상이 몰카냐? 메걸리안들 생각...                 True   \n",
       "...                                                 ...                  ...   \n",
       "7891                                      힘내세요~ 응원합니다!!                False   \n",
       "7892                             힘내세요~~삼가 고인의 명복을 빕니다..                False   \n",
       "7893                              힘내세용 ^^ 항상 응원합니닷 ^^ !                False   \n",
       "7894  힘내소...연기로 답해요.나도 53살 인데 이런일 저런일 다 있더라구요.인격을 믿습...                False   \n",
       "7895                                 힘들면 관뒀어야지 그게 현명한거다                False   \n",
       "\n",
       "        bias  hate                                            english  \n",
       "0     others  hate  (How the current hotel owner feels) Ah 18 I go...  \n",
       "1       none  none  ....the representative of Korean beauty...so p...  \n",
       "2       none  hate  ...Naughty people...People who enjoyed other p...  \n",
       "3       none  none  Episodes 1 and 2 were awkward, but after episo...  \n",
       "4     gender  hate  1. Scratching a person’s face with a fingernai...  \n",
       "...      ...   ...                                                ...  \n",
       "7891    none  none                    Cheer up~ I’m rooting for you!!  \n",
       "7892    none  none  Cheer up~~ I pray that the deceased rest in pe...  \n",
       "7893    none  none          Cheer up ^^ I will always support you ^^!  \n",
       "7894    none  none  Cheer up... I'll answer with acting. I'm 53 ye...  \n",
       "7895    none  none        If it's hard, you should quit. That's wise.  \n",
       "\n",
       "[7896 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korean_data = pd.read_csv('korean.csv',sep = \",\")\n",
    "korean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='hate'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjEAAAHiCAYAAAAZLZ3oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxo0lEQVR4nO3de1TVdb7/8deOm0rwVVRu406dvKQHbTpaCKcMb6gzRGUnnSjMhjTTdBhlWdaZM9a0xOykTnqOOa4Kr1HNZM0cbRvmpUzxQnHylstMCwvEC+wtSqCwf3+0+v7aghambj7wfKz1XYv9+b73l/e3du0Xn+/N4fV6vQIAADDMNf5uAAAA4FIQYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARgr0dwNXSm1trb755huFhYXJ4XD4ux0AAPATeL1enTp1SrGxsbrmmovPtTTZEPPNN9/I6XT6uw0AAHAJioqK1KFDh4vWNNkQExYWJum7fwjh4eF+7gYAAPwUHo9HTqfT/h6/mCYbYr4/hBQeHk6IAQDAMD/lVBBO7AUAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARmpQiFm4cKF69+5t3wU3ISFB7777rr1+zJgxcjgcPku/fv18tlFVVaVJkyapXbt2Cg0NVWpqqo4cOeJTU1ZWpvT0dFmWJcuylJ6ervLy8kvfSwAA0OQ0KMR06NBBs2bN0s6dO7Vz504NHDhQd955p/bs2WPXDBs2TMXFxfayZs0an21kZmZq1apVys3N1ebNm1VRUaGUlBTV1NTYNWlpaSosLJTL5ZLL5VJhYaHS09N/5q4CAICmxOH1er0/ZwMRERF6/vnnlZGRoTFjxqi8vFxvv/12vbVut1vt27fXsmXLNGrUKEn//2nTa9as0dChQ7Vv3z717NlT+fn5io+PlyTl5+crISFBn332mbp37/6T+vJ4PLIsS263m2cnAQBgiIZ8f1/yOTE1NTXKzc3V6dOnlZCQYI9v3LhRkZGR6tatm8aOHavS0lJ7XUFBgc6ePavk5GR7LDY2VnFxcdqyZYskaevWrbIsyw4wktSvXz9ZlmXX1Keqqkoej8dnAQAATVeDQ8yuXbt07bXXKiQkROPHj9eqVavUs2dPSdLw4cO1YsUKrV+/Xi+88IJ27NihgQMHqqqqSpJUUlKi4OBgtWnTxmebUVFRKikpsWsiIyPr/N7IyEi7pj7Z2dn2OTSWZcnpdDZ01wAAgEECG/qG7t27q7CwUOXl5fr73/+uBx98UJs2bVLPnj3tQ0SSFBcXp759+6pjx45avXq1RowYccFter1en0du1/f47fNrzjd9+nRNmTLFfu3xeIwJMp2eWO3vFpqEw7N+4+8WAABXUYNDTHBwsLp06SJJ6tu3r3bs2KG//OUvWrRoUZ3amJgYdezYUQcOHJAkRUdHq7q6WmVlZT6zMaWlpUpMTLRrjh49Wmdbx44dU1RU1AX7CgkJUUhISEN3BwAAGOpn3yfG6/Xah4vOd+LECRUVFSkmJkaS1KdPHwUFBSkvL8+uKS4u1u7du+0Qk5CQILfbre3bt9s127Ztk9vttmsAAAAaNBPz5JNPavjw4XI6nTp16pRyc3O1ceNGuVwuVVRUaMaMGbrnnnsUExOjw4cP68knn1S7du109913S5Isy1JGRoamTp2qtm3bKiIiQllZWerVq5cGDx4sSerRo4eGDRumsWPH2rM748aNU0pKyk++MgkAADR9DQoxR48eVXp6uoqLi2VZlnr37i2Xy6UhQ4aosrJSu3bt0tKlS1VeXq6YmBgNGDBAr7/+usLCwuxtzJ07V4GBgRo5cqQqKys1aNAg5eTkKCAgwK5ZsWKFJk+ebF/FlJqaqgULFlymXQYAAE3Bz75PTGNl0n1iOLH38uDEXgAw31W5TwwAAIA/EWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjNSgELNw4UL17t1b4eHhCg8PV0JCgt599117vdfr1YwZMxQbG6uWLVsqKSlJe/bs8dlGVVWVJk2apHbt2ik0NFSpqak6cuSIT01ZWZnS09NlWZYsy1J6errKy8svfS8BAECT06AQ06FDB82aNUs7d+7Uzp07NXDgQN155512UJk9e7bmzJmjBQsWaMeOHYqOjtaQIUN06tQpexuZmZlatWqVcnNztXnzZlVUVCglJUU1NTV2TVpamgoLC+VyueRyuVRYWKj09PTLtMsAAKApcHi9Xu/P2UBERISef/55/e53v1NsbKwyMzP1+OOPS/pu1iUqKkrPPfecHnnkEbndbrVv317Lli3TqFGjJEnffPONnE6n1qxZo6FDh2rfvn3q2bOn8vPzFR8fL0nKz89XQkKCPvvsM3Xv3v0n9eXxeGRZltxut8LDw3/OLl5xnZ5Y7e8WmoTDs37j7xYAAD9TQ76/L/mcmJqaGuXm5ur06dNKSEjQoUOHVFJSouTkZLsmJCREt99+u7Zs2SJJKigo0NmzZ31qYmNjFRcXZ9ds3bpVlmXZAUaS+vXrJ8uy7Jr6VFVVyePx+CwAAKDpanCI2bVrl6699lqFhIRo/PjxWrVqlXr27KmSkhJJUlRUlE99VFSUva6kpETBwcFq06bNRWsiIyPr/N7IyEi7pj7Z2dn2OTSWZcnpdDZ01wAAgEEaHGK6d++uwsJC5efn69FHH9WDDz6ovXv32usdDodPvdfrrTN2vvNr6qv/se1Mnz5dbrfbXoqKin7qLgEAAAM1OMQEBwerS5cu6tu3r7Kzs3XjjTfqL3/5i6KjoyWpzmxJaWmpPTsTHR2t6upqlZWVXbTm6NGjdX7vsWPH6szy/FBISIh91dT3CwAAaLp+9n1ivF6vqqqq1LlzZ0VHRysvL89eV11drU2bNikxMVGS1KdPHwUFBfnUFBcXa/fu3XZNQkKC3G63tm/fbtds27ZNbrfbrgEAAAhsSPGTTz6p4cOHy+l06tSpU8rNzdXGjRvlcrnkcDiUmZmpmTNnqmvXruratatmzpypVq1aKS0tTZJkWZYyMjI0depUtW3bVhEREcrKylKvXr00ePBgSVKPHj00bNgwjR07VosWLZIkjRs3TikpKT/5yiQAAND0NSjEHD16VOnp6SouLpZlWerdu7dcLpeGDBkiSZo2bZoqKys1YcIElZWVKT4+Xu+9957CwsLsbcydO1eBgYEaOXKkKisrNWjQIOXk5CggIMCuWbFihSZPnmxfxZSamqoFCxZcjv0FAABNxM++T0xjxX1imh/uEwMA5rsq94kBAADwJ0IMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEgNCjHZ2dm6+eabFRYWpsjISN11113av3+/T82YMWPkcDh8ln79+vnUVFVVadKkSWrXrp1CQ0OVmpqqI0eO+NSUlZUpPT1dlmXJsiylp6ervLz80vYSAAA0OQ0KMZs2bdLEiROVn5+vvLw8nTt3TsnJyTp9+rRP3bBhw1RcXGwva9as8VmfmZmpVatWKTc3V5s3b1ZFRYVSUlJUU1Nj16SlpamwsFAul0sul0uFhYVKT0//GbsKAACaksCGFLtcLp/Xr776qiIjI1VQUKD+/fvb4yEhIYqOjq53G263Wy+//LKWLVumwYMHS5KWL18up9OpdevWaejQodq3b59cLpfy8/MVHx8vSVq8eLESEhK0f/9+de/evUE7CQAAmp6fdU6M2+2WJEVERPiMb9y4UZGRkerWrZvGjh2r0tJSe11BQYHOnj2r5ORkeyw2NlZxcXHasmWLJGnr1q2yLMsOMJLUr18/WZZl15yvqqpKHo/HZwEAAE1Xg2Zifsjr9WrKlCm69dZbFRcXZ48PHz5c9957rzp27KhDhw7pj3/8owYOHKiCggKFhISopKREwcHBatOmjc/2oqKiVFJSIkkqKSlRZGRknd8ZGRlp15wvOztbTz/99KXuDoAf6PTEan+30GQcnvUbf7cANFmXHGIee+wxffrpp9q8ebPP+KhRo+yf4+Li1LdvX3Xs2FGrV6/WiBEjLrg9r9crh8Nhv/7hzxeq+aHp06drypQp9muPxyOn0/mT9wcAAJjlkg4nTZo0Sf/4xz+0YcMGdejQ4aK1MTEx6tixow4cOCBJio6OVnV1tcrKynzqSktLFRUVZdccPXq0zraOHTtm15wvJCRE4eHhPgsAAGi6GhRivF6vHnvsMb311ltav369Onfu/KPvOXHihIqKihQTEyNJ6tOnj4KCgpSXl2fXFBcXa/fu3UpMTJQkJSQkyO12a/v27XbNtm3b5Ha77RoAANC8Nehw0sSJE7Vy5Uq98847CgsLs89PsSxLLVu2VEVFhWbMmKF77rlHMTExOnz4sJ588km1a9dOd999t12bkZGhqVOnqm3btoqIiFBWVpZ69eplX63Uo0cPDRs2TGPHjtWiRYskSePGjVNKSgpXJgEAAEkNDDELFy6UJCUlJfmMv/rqqxozZowCAgK0a9cuLV26VOXl5YqJidGAAQP0+uuvKywszK6fO3euAgMDNXLkSFVWVmrQoEHKyclRQECAXbNixQpNnjzZvoopNTVVCxYsuNT9BAAATUyDQozX673o+pYtW2rt2rU/up0WLVpo/vz5mj9//gVrIiIitHz58oa0BwAAmhGenQQAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwUoNCTHZ2tm6++WaFhYUpMjJSd911l/bv3+9T4/V6NWPGDMXGxqply5ZKSkrSnj17fGqqqqo0adIktWvXTqGhoUpNTdWRI0d8asrKypSeni7LsmRZltLT01VeXn5pewkAAJqcBoWYTZs2aeLEicrPz1deXp7OnTun5ORknT592q6ZPXu25syZowULFmjHjh2Kjo7WkCFDdOrUKbsmMzNTq1atUm5urjZv3qyKigqlpKSopqbGrklLS1NhYaFcLpdcLpcKCwuVnp5+GXYZAAA0BQ6v1+u91DcfO3ZMkZGR2rRpk/r37y+v16vY2FhlZmbq8ccfl/TdrEtUVJSee+45PfLII3K73Wrfvr2WLVumUaNGSZK++eYbOZ1OrVmzRkOHDtW+ffvUs2dP5efnKz4+XpKUn5+vhIQEffbZZ+revfuP9ubxeGRZltxut8LDwy91F6+KTk+s9ncLTcLhWb/xdwtNBp/Jy4fPJdAwDfn+/lnnxLjdbklSRESEJOnQoUMqKSlRcnKyXRMSEqLbb79dW7ZskSQVFBTo7NmzPjWxsbGKi4uza7Zu3SrLsuwAI0n9+vWTZVl2zfmqqqrk8Xh8FgAA0HRdcojxer2aMmWKbr31VsXFxUmSSkpKJElRUVE+tVFRUfa6kpISBQcHq02bNhetiYyMrPM7IyMj7ZrzZWdn2+fPWJYlp9N5qbsGAAAMcMkh5rHHHtOnn36q1157rc46h8Ph89rr9dYZO9/5NfXVX2w706dPl9vttpeioqKfshsAAMBQlxRiJk2apH/84x/asGGDOnToYI9HR0dLUp3ZktLSUnt2Jjo6WtXV1SorK7tozdGjR+v83mPHjtWZ5fleSEiIwsPDfRYAANB0NSjEeL1ePfbYY3rrrbe0fv16de7c2Wd9586dFR0drby8PHusurpamzZtUmJioiSpT58+CgoK8qkpLi7W7t277ZqEhAS53W5t377drtm2bZvcbrddAwAAmrfAhhRPnDhRK1eu1DvvvKOwsDB7xsWyLLVs2VIOh0OZmZmaOXOmunbtqq5du2rmzJlq1aqV0tLS7NqMjAxNnTpVbdu2VUREhLKystSrVy8NHjxYktSjRw8NGzZMY8eO1aJFiyRJ48aNU0pKyk+6MgkAADR9DQoxCxculCQlJSX5jL/66qsaM2aMJGnatGmqrKzUhAkTVFZWpvj4eL333nsKCwuz6+fOnavAwECNHDlSlZWVGjRokHJychQQEGDXrFixQpMnT7avYkpNTdWCBQsuZR8BAEAT9LPuE9OYcZ+Y5of7cVw+fCYvHz6XQMNctfvEAAAA+AshBgAAGKlB58QAAOAPHOK8fJrSIU5mYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYqcEh5oMPPtAdd9yh2NhYORwOvf322z7rx4wZI4fD4bP069fPp6aqqkqTJk1Su3btFBoaqtTUVB05csSnpqysTOnp6bIsS5ZlKT09XeXl5Q3eQQAA0DQ1OMScPn1aN954oxYsWHDBmmHDhqm4uNhe1qxZ47M+MzNTq1atUm5urjZv3qyKigqlpKSopqbGrklLS1NhYaFcLpdcLpcKCwuVnp7e0HYBAEATFdjQNwwfPlzDhw+/aE1ISIiio6PrXed2u/Xyyy9r2bJlGjx4sCRp+fLlcjqdWrdunYYOHap9+/bJ5XIpPz9f8fHxkqTFixcrISFB+/fvV/fu3RvaNgAAaGKuyDkxGzduVGRkpLp166axY8eqtLTUXldQUKCzZ88qOTnZHouNjVVcXJy2bNkiSdq6dassy7IDjCT169dPlmXZNeerqqqSx+PxWQAAQNN12UPM8OHDtWLFCq1fv14vvPCCduzYoYEDB6qqqkqSVFJSouDgYLVp08bnfVFRUSopKbFrIiMj62w7MjLSrjlfdna2ff6MZVlyOp2Xec8AAEBj0uDDST9m1KhR9s9xcXHq27evOnbsqNWrV2vEiBEXfJ/X65XD4bBf//DnC9X80PTp0zVlyhT7tcfjIcgAANCEXfFLrGNiYtSxY0cdOHBAkhQdHa3q6mqVlZX51JWWlioqKsquOXr0aJ1tHTt2zK45X0hIiMLDw30WAADQdF3xEHPixAkVFRUpJiZGktSnTx8FBQUpLy/PrikuLtbu3buVmJgoSUpISJDb7db27dvtmm3btsntdts1AACgeWvw4aSKigp9/vnn9utDhw6psLBQERERioiI0IwZM3TPPfcoJiZGhw8f1pNPPql27drp7rvvliRZlqWMjAxNnTpVbdu2VUREhLKystSrVy/7aqUePXpo2LBhGjt2rBYtWiRJGjdunFJSUrgyCQAASLqEELNz504NGDDAfv39eSgPPvigFi5cqF27dmnp0qUqLy9XTEyMBgwYoNdff11hYWH2e+bOnavAwECNHDlSlZWVGjRokHJychQQEGDXrFixQpMnT7avYkpNTb3ovWkAAEDz0uAQk5SUJK/Xe8H1a9eu/dFttGjRQvPnz9f8+fMvWBMREaHly5c3tD0AANBM8OwkAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEaHGI++OAD3XHHHYqNjZXD4dDbb7/ts97r9WrGjBmKjY1Vy5YtlZSUpD179vjUVFVVadKkSWrXrp1CQ0OVmpqqI0eO+NSUlZUpPT1dlmXJsiylp6ervLy8wTsIAACapgaHmNOnT+vGG2/UggUL6l0/e/ZszZkzRwsWLNCOHTsUHR2tIUOG6NSpU3ZNZmamVq1apdzcXG3evFkVFRVKSUlRTU2NXZOWlqbCwkK5XC65XC4VFhYqPT39EnYRAAA0RYENfcPw4cM1fPjwetd5vV7NmzdPTz31lEaMGCFJWrJkiaKiorRy5Uo98sgjcrvdevnll7Vs2TINHjxYkrR8+XI5nU6tW7dOQ4cO1b59++RyuZSfn6/4+HhJ0uLFi5WQkKD9+/ere/ful7q/AACgibis58QcOnRIJSUlSk5OtsdCQkJ0++23a8uWLZKkgoICnT171qcmNjZWcXFxds3WrVtlWZYdYCSpX79+sizLrjlfVVWVPB6PzwIAAJquyxpiSkpKJElRUVE+41FRUfa6kpISBQcHq02bNhetiYyMrLP9yMhIu+Z82dnZ9vkzlmXJ6XT+7P0BAACN1xW5OsnhcPi89nq9dcbOd35NffUX28706dPldrvtpaio6BI6BwAAprisISY6OlqS6syWlJaW2rMz0dHRqq6uVllZ2UVrjh49Wmf7x44dqzPL872QkBCFh4f7LAAAoOm6rCGmc+fOio6OVl5enj1WXV2tTZs2KTExUZLUp08fBQUF+dQUFxdr9+7ddk1CQoLcbre2b99u12zbtk1ut9uuAQAAzVuDr06qqKjQ559/br8+dOiQCgsLFRERoeuuu06ZmZmaOXOmunbtqq5du2rmzJlq1aqV0tLSJEmWZSkjI0NTp05V27ZtFRERoaysLPXq1cu+WqlHjx4aNmyYxo4dq0WLFkmSxo0bp5SUFK5MAgAAki4hxOzcuVMDBgywX0+ZMkWS9OCDDyonJ0fTpk1TZWWlJkyYoLKyMsXHx+u9995TWFiY/Z65c+cqMDBQI0eOVGVlpQYNGqScnBwFBATYNStWrNDkyZPtq5hSU1MveG8aAADQ/Di8Xq/X301cCR6PR5Zlye12N/rzYzo9sdrfLTQJh2f9xt8tNBl8Ji8fPpeXB5/Jy6exfyYb8v3Ns5MAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAI132EDNjxgw5HA6fJTo62l7v9Xo1Y8YMxcbGqmXLlkpKStKePXt8tlFVVaVJkyapXbt2Cg0NVWpqqo4cOXK5WwUAAAa7IjMx//Iv/6Li4mJ72bVrl71u9uzZmjNnjhYsWKAdO3YoOjpaQ4YM0alTp+yazMxMrVq1Srm5udq8ebMqKiqUkpKimpqaK9EuAAAwUOAV2WhgoM/sy/e8Xq/mzZunp556SiNGjJAkLVmyRFFRUVq5cqUeeeQRud1uvfzyy1q2bJkGDx4sSVq+fLmcTqfWrVunoUOHXomWAQCAYa7ITMyBAwcUGxurzp0767e//a2++OILSdKhQ4dUUlKi5ORkuzYkJES33367tmzZIkkqKCjQ2bNnfWpiY2MVFxdn19SnqqpKHo/HZwEAAE3XZQ8x8fHxWrp0qdauXavFixerpKREiYmJOnHihEpKSiRJUVFRPu+Jioqy15WUlCg4OFht2rS5YE19srOzZVmWvTidzsu8ZwAAoDG57CFm+PDhuueee9SrVy8NHjxYq1evlvTdYaPvORwOn/d4vd46Y+f7sZrp06fL7XbbS1FR0c/YCwAA0Nhd8UusQ0ND1atXLx04cMA+T+b8GZXS0lJ7diY6OlrV1dUqKyu7YE19QkJCFB4e7rMAAICm64qHmKqqKu3bt08xMTHq3LmzoqOjlZeXZ6+vrq7Wpk2blJiYKEnq06ePgoKCfGqKi4u1e/duuwYAAOCyX52UlZWlO+64Q9ddd51KS0v17LPPyuPx6MEHH5TD4VBmZqZmzpyprl27qmvXrpo5c6ZatWqltLQ0SZJlWcrIyNDUqVPVtm1bRUREKCsryz48BQAAIF2BEHPkyBHdd999On78uNq3b69+/fopPz9fHTt2lCRNmzZNlZWVmjBhgsrKyhQfH6/33ntPYWFh9jbmzp2rwMBAjRw5UpWVlRo0aJBycnIUEBBwudsFAACGuuwhJjc396LrHQ6HZsyYoRkzZlywpkWLFpo/f77mz59/mbsDAABNBc9OAgAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABiJEAMAAIxEiAEAAEYixAAAACMRYgAAgJEIMQAAwEiEGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACMRIgBAABGIsQAAAAjEWIAAICRCDEAAMBIhBgAAGAkQgwAADASIQYAABip0YeY//mf/1Hnzp3VokUL9enTRx9++KG/WwIAAI1Aow4xr7/+ujIzM/XUU0/pk08+0W233abhw4frq6++8ndrAADAzxp1iJkzZ44yMjL08MMPq0ePHpo3b56cTqcWLlzo79YAAICfBfq7gQuprq5WQUGBnnjiCZ/x5ORkbdmypU59VVWVqqqq7Ndut1uS5PF4rmyjl0Ft1Rl/t9AkmPDv2hR8Ji8fPpeXB5/Jy6exfya/78/r9f5obaMNMcePH1dNTY2ioqJ8xqOiolRSUlKnPjs7W08//XSdcafTecV6RONizfN3B0BdfC7R2JjymTx16pQsy7poTaMNMd9zOBw+r71eb50xSZo+fbqmTJliv66trdXJkyfVtm3beuvx03k8HjmdThUVFSk8PNzf7QB8JtEo8bm8PLxer06dOqXY2NgfrW20IaZdu3YKCAioM+tSWlpaZ3ZGkkJCQhQSEuIz1rp16yvZYrMTHh7Of5hoVPhMojHic/nz/dgMzPca7Ym9wcHB6tOnj/Ly8nzG8/LylJiY6KeuAABAY9FoZ2IkacqUKUpPT1ffvn2VkJCgv/71r/rqq680fvx4f7cGAAD8rFGHmFGjRunEiRN65plnVFxcrLi4OK1Zs0YdO3b0d2vNSkhIiP70pz/VOVwH+AufSTRGfC6vPof3p1zDBAAA0Mg02nNiAAAALoYQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAMb48MMP9cADDyghIUFff/21JGnZsmXavHmznzsD4A+EGFwQXxhoTP7+979r6NChatmypT755BNVVVVJ+u5JtzNnzvRzd2jODh48qP/4j//Qfffdp9LSUkmSy+XSnj17/NxZ00eIQb34wkBj8+yzz+qll17S4sWLFRQUZI8nJibq448/9mNnaM42bdqkXr16adu2bXrrrbdUUVEhSfr000/1pz/9yc/dNX2EGNSLLww0Nvv371f//v3rjIeHh6u8vPzqNwRIeuKJJ/Tss88qLy9PwcHB9viAAQO0detWP3bWPBBiUC++MNDYxMTE6PPPP68zvnnzZv3yl7/0Q0eAtGvXLt199911xtu3b68TJ074oaPmhRCDevGFgcbmkUce0e9//3tt27ZNDodD33zzjVasWKGsrCxNmDDB3+2hmWrdurWKi4vrjH/yySf6xS9+4YeOmpdG/RRr+M/3XxivvPKK/YWxdetWZWVl6T//8z/93R6aoWnTpsntdmvAgAH69ttv1b9/f4WEhCgrK0uPPfaYv9tDM5WWlqbHH39cb775phwOh2pra/XRRx8pKytLo0eP9nd7TR5PscYFPfXUU5o7d66+/fZbSbK/MP785z/7uTM0Z2fOnNHevXtVW1urnj176tprr/V3S2jGzp49qzFjxig3N1der1eBgYGqqalRWlqacnJyFBAQ4O8WmzRCDC6KLww0FkuWLNG///u/KzQ01N+tAHV88cUX+vjjj1VbW6ubbrpJXbt29XdLzQIhBoAR2rdvrzNnzuiOO+7QAw88oGHDhikwkCPi8K9nnnlGWVlZatWqlc94ZWWlnn/+eQ6/X2GEGNTr9OnTmjVrlt5//32VlpaqtrbWZ/0XX3zhp87QXJ07d04ul0uvvfaa3nnnHbVs2VL33nuvHnjgASUmJvq7PTRTAQEBKi4uVmRkpM/4iRMnFBkZqZqaGj911jzwZwzq9fDDD2vTpk1KT09XTEyMHA6Hv1tCMxcYGKiUlBSlpKTozJkzWrVqlVauXKkBAwaoQ4cOOnjwoL9bRDPk9Xrr/f/j//3f/ykiIsIPHTUvhBjU691339Xq1av1b//2b/5uBaijVatWGjp0qMrKyvTll19q3759/m4JzUybNm3kcDjkcDjUrVs3nyBTU1OjiooKjR8/3o8dNg+EGNSrTZs2/BWBRuf7GZgVK1Zo3bp1cjqduu+++/Tmm2/6uzU0M/PmzZPX69Xvfvc7Pf3007Isy14XHBysTp06KSEhwY8dNg+cE4N6LV++XO+8846WLFlS54Q1wB/uu+8+/fOf/1SrVq1077336v777+dcGPjdpk2blJiY6PN4Flw9hBjU66abbtLBgwfl9XrVqVOnOv+B8vwkXG1paWm6//77NXToUK5KQqNUWVmps2fP+oyFh4f7qZvmgf8ToF533XWXv1sAfKxcudLfLQB1nDlzRtOmTdMbb7xR77OSuDrpymImBkCj9eKLL2rcuHFq0aKFXnzxxYvWTp48+Sp1Bfx/EydO1IYNG/TMM89o9OjR+u///m99/fXXWrRokWbNmqX777/f3y02aYQYXFRBQYH27dsnh8Ohnj176qabbvJ3S2hGOnfurJ07d6pt27bq3LnzBescDgf3LoJfXHfddVq6dKmSkpIUHh6ujz/+WF26dNGyZcv02muvac2aNf5usUnjcBLqVVpaqt/+9rfauHGjWrduLa/Xaz98Lzc3V+3bt/d3i2gGDh06VO/PQGNx8uRJO2CHh4fr5MmTkqRbb71Vjz76qD9baxau8XcDaJwmTZokj8ejPXv26OTJkyorK9Pu3bvl8XiYtkejUFNTo8LCQpWVlfm7FTRjv/zlL3X48GFJUs+ePfXGG29Ikv75z3+qdevW/musmeBwEuplWZbWrVunm2++2Wd8+/btSk5OVnl5uX8aQ7OVmZmpXr16KSMjQzU1Nerfv7+2bt2qVq1a6X//93+VlJTk7xbRDM2dO1cBAQGaPHmyNmzYoN/85jeqqanRuXPnNGfOHP3+97/3d4tNGoeTUK/a2tp673sQFBRU5zlKwNXwt7/9TQ888ICk7/7KPXz4sD777DMtXbpUTz31lD766CM/d4jm6A9/+IP984ABA/TZZ59p586duv7663XjjTf6sbPmgZkY1OvOO+9UeXm5XnvtNcXGxkqSvv76a91///1q06aNVq1a5ecO0dy0aNFCn3/+uTp06KBx48apVatWmjdvng4dOqQbb7xRHo/H3y2imXr//fcv+LDcV155xU9dNQ+cE4N6LViwQKdOnVKnTp10/fXXq0uXLurUqZNOnTr1o5e6AldCVFSU9u7dq5qaGrlcLg0ePFjSd/fpCAgI8HN3aK6efvppJScn6/3339fx48dVVlbms+DK4nAS6uV0OvXxxx9r3bp12rdvn7xer3r27Gl/cQBX20MPPaSRI0faT1UfMmSIJGnbtm264YYb/NwdmquXXnpJOTk5Sk9P93crzRKHk3BBTJGisfnb3/6moqIi3XvvverQoYMkacmSJWrdurXuvPNOP3eH5qht27bavn27rr/+en+30iwRYlCvp59+Ws8884z69u1r/+X7Q5wTAwDS448/rmuvvVZ//OMf/d1Ks0SIQb1iYmI0e/ZspkjRqDA7iMZgypQp9s+1tbVasmSJevfurd69e9e5qnPOnDlXu71mhXNiUK/q6molJib6uw3A9mOzg8DV8sknn/i8/tWvfiVJ2r17t884n9Erj5kY1IspUjQ2zA4COB8zMajXt99+q7/+9a9at24dU6RoFJgdBHA+ZmJQrwEDBlxwncPh0Pr1669iNwCzgwDqYiYG9dqwYYO/WwB8MDsI4HzMxAAwArODAM5HiAEAAEbi2UkAjPL5559r7dq1qqyslCTxdxjQfBFiABjhxIkTGjRokLp166Zf//rXKi4uliQ9/PDDmjp1qp+7A+APhBgARvjDH/6goKAgffXVV2rVqpU9PmrUKLlcLj92BsBfuDoJgBHee+89rV271n7w4/e6du2qL7/80k9dAfAnZmIAGOH06dM+MzDfO378uEJCQvzQEQB/I8QAMEL//v21dOlS+7XD4VBtba2ef/75i15+DaDp4hJrAEbYu3evkpKS1KdPH61fv16pqanas2ePTp48qY8++kjXX3+9v1sEcJURYgAYo6SkRAsXLlRBQYFqa2v1r//6r5o4caJiYmL83RoAPyDEAGi0RowYoZycHIWHh2vp0qUaNWoU578AsBFiADRawcHB+vLLLxUTE6OAgAAVFxcrMjLS320BaCS4xBpAo3XDDTdo+vTpGjBggLxer9544w2Fh4fXWzt69Oir3B0Af2MmBkCj9dFHH2nq1Kk6ePCgTp48qbCwMDkcjjp1DodDJ0+e9EOHAPyJEAPACNdcc41KSko4nATAxn1iADRaI0aMkMfjkSS9+uqrCgsL83NHABoTZmIANFqc2AvgYjixF0CjxYm9AC6GmRgAjdaWLVs0ZcoUTuwFUC9CDAAjXHPNNSouLlZUVJS/WwHQSBBiABjhyy+/VHh4uF555RXt27dPDodDPXv2VEZGxgUPMQFo2ggxAIywc+dODR06VC1bttQtt9wir9ernTt3qrKyUmvXrlWfPn383SKAq4wQA8AIt912m7p06aLFixcrMPC7axLOnTunhx9+WF988YU++OADP3cI4GojxAAwQsuWLfXJJ5/ohhtu8Bnfu3ev+vbtqzNnzvipMwD+ws3uABghPDxcX331VZ3xoqIiboIHNFOEGABGGDVqlDIyMvT666+rqKhIR44cUW5urh5++GHdd999/m4PgB9wszsARviv//ovORwOjR49WufOnZMkBQUF6dFHH9WsWbP83B0Af+CcGABGOXPmjA4ePCiv16suXbqoVatW/m4JgJ8QYgAAgJE4JwYAABiJEAMAAIxEiAEAAEYixADwq6SkJGVmZvq7DQAGIsQAMFpOTo5at27t7zYA+AEhBgAAGIkQA8DvamtrNW3aNEVERCg6OlozZsyw182ZM0e9evVSaGionE6nJkyYoIqKCknSxo0b9dBDD8ntdsvhcMjhcNjvra6u1rRp0/SLX/xCoaGhio+P18aNG6/+zgG4YggxAPxuyZIlCg0N1bZt2zR79mw988wzysvLkyRdc801evHFF7V7924tWbJE69ev17Rp0yRJiYmJmjdvnsLDw1VcXKzi4mJlZWVJkh566CF99NFHys3N1aeffqp7771Xw4YN04EDB/y2nwAuL252B8CvkpKSVFNTow8//NAeu+WWWzRw4MB6Hyfw5ptv6tFHH9Xx48clfXdOTGZmpsrLy+2agwcPqmvXrjpy5IhiY2Pt8cGDB+uWW27RzJkzr9wOAbhqeHYSAL/r3bu3z+uYmBiVlpZKkjZs2KCZM2dq79698ng8OnfunL799ludPn1aoaGh9W7v448/ltfrVbdu3XzGq6qq1LZt2yuzEwCuOkIMAL8LCgryee1wOFRbW6svv/xSv/71rzV+/Hj9+c9/VkREhDZv3qyMjAydPXv2gturra1VQECACgoKFBAQ4LPu2muvvSL7AODqI8QAaLR27typc+fO6YUXXtA113x3Ct8bb7zhUxMcHKyamhqfsZtuukk1NTUqLS3VbbfddtX6BXB1cWIvgEbr+uuv17lz5zR//nx98cUXWrZsmV566SWfmk6dOqmiokLvv/++jh8/rjNnzqhbt266//77NXr0aL311ls6dOiQduzYoeeee05r1qzx094AuNwIMQAarV/96leaM2eOnnvuOcXFxWnFihXKzs72qUlMTNT48eM1atQotW/fXrNnz5Ykvfrqqxo9erSmTp2q7t27KzU1Vdu2bZPT6fTHrgC4Arg6CQAAGImZGAAAYCRCDAAAMBIhBgAAGIkQAwAAjESIAQAARiLEAAAAIxFiAACAkQgxAADASIQYAABgJEIMAAAwEiEGAAAYiRADAACM9P8ABeqRzjjRqmgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "korean_hate_counts = korean_data['hate'].value_counts()\n",
    "korean_hate_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine_tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197f8f55c1f34d43b8043726e25bd304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339a38583f954618ac04240be0b82734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5494 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_class = multi_class.rename(columns={'multi_class': 'label'})\n",
    "\n",
    "train_test = Dataset.from_pandas(berkeley_compressed).train_test_split(test_size=0.1)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True) \n",
    "\n",
    "tokenized_data = train_test.map(preprocess, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/slurm-14097/ipykernel_117425/2210602446.py:27: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=15)\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hatespeech_classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2242\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2243\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2244\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2245\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2246\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs, num_items_in_batch\u001b[38;5;241m=\u001b[39mnum_items_in_batch)\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:3780\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[0;32m-> 3780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3781\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3782\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3783\u001b[0m         )\n\u001b[1;32m   3784\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[1;32m   3785\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training multi_lable BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14064/ipykernel_76594/3649219314.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shortened_berkeley[\"labels\"] = shortened_berkeley[\"labels\"].apply(lambda x: np.array(x, dtype=np.int64))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bc4bbac0e64f1881ef59e50d416ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da5082346cd4cd0b4c4c0848500c651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b832952f8ef4309b926279db4a1481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d7c941e3df4ad69e8e09ffa82207cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13556 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoConfig\n",
    "\n",
    "#berkeley_compressed = berkeley_compressed.rename(columns={'hatespeech': 'label'})\n",
    "berkeley_compressed[demographic_labels] = berkeley_compressed[demographic_labels].astype(int)\n",
    "berkeley_compressed['labels'] = berkeley_compressed[demographic_labels].astype(float).values.tolist()\n",
    "train_test = Dataset.from_pandas(berkeley_compressed).train_test_split(test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shortened_berkeley = berkeley_compressed.head(100)\n",
    "shortened_berkeley[\"labels\"] = shortened_berkeley[\"labels\"].apply(lambda x: np.array(x, dtype=np.int64))\n",
    "shortened_berkeley = shortened_berkeley[[\"text\", \"labels\"]]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "features = Features({\n",
    "    \"text\": Value(\"string\"),\n",
    "    \"labels\": Sequence(Value(\"float32\"))  \n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "shortened_train_test = Dataset.from_pandas(berkeley_compressed).train_test_split(test_size=0.1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples[\"text\"], truncation=True) \n",
    "    tokenized[\"labels\"] = examples[\"labels\"]\n",
    "    return tokenized\n",
    "\n",
    "tokenized_data = train_test.map(preprocess, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "shortened_tokenized_data = shortened_train_test.map(preprocess, batched = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14064/ipykernel_76594/2049454021.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  shortened_berkeley[\"labels\"] = shortened_berkeley[\"labels\"].apply(lambda x: np.array(x, dtype=np.int64))\n"
     ]
    }
   ],
   "source": [
    "shortened_berkeley = berkeley_compressed.head(100)\n",
    "shortened_berkeley[\"labels\"] = shortened_berkeley[\"labels\"].apply(lambda x: np.array(x, dtype=np.int64))\n",
    "shortened_berkeley = shortened_berkeley[[\"text\", \"labels\"]]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "features = Features({\n",
    "    \"text\": Value(\"string\"),\n",
    "    \"labels\": Sequence(Value(\"float32\"))  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/scratch/slurm-14064/ipykernel_76594/1718452880.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38125' max='38125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38125/38125 51:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.092587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>0.089761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.090460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.093913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.097674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=38125, training_loss=0.0879882236918465, metrics={'train_runtime': 3062.4352, 'train_samples_per_second': 199.188, 'train_steps_per_second': 12.449, 'total_flos': 1.5802946869776e+16, 'train_loss': 0.0879882236918465, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=20, problem_type=\"multi_label_classification\")\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits))\n",
    "    preds = (probs > 0.5).int().numpy()\n",
    "    return {\n",
    "        \"f1_micro\": f1.compute(predictions=preds, references=labels, average=\"micro\")[\"f1\"],\n",
    "        \"precision_micro\": precision.compute(predictions=preds, references=labels, average=\"micro\")[\"precision\"],\n",
    "        \"recall_micro\": recall.compute(predictions=preds, references=labels, average=\"micro\")[\"recall\"],\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hatespeech_classifier\",\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "#torch.mps.empty_cache()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "#results = trainer.evaluate(tokenized_data['test'])\n",
    "#pd.DataFrame(results, index=['Fine-tuned DistilBERT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifying text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_category(text):\n",
    "    predict_input = tokenizer.encode(text,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors=\"tf\")\n",
    "    output = model(predict_input)[0]\n",
    "    prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    "    return prediction_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_data = unlabelled_df[‘data’].to_list()\n",
    "len(unlabelled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_predictions = []\n",
    "for data in unlabelled_data:\n",
    "    unlabelled_predictions.append(predict_category(data))\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"data\": unlabelled_data,\n",
    "        \"labels\": unlabelled_predictions,\n",
    "    })\n",
    "prediction_df.to_csv(\"model_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5846"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic_en = arabic_data['english'].to_list()\n",
    "len(arabic_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m arabic_predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m arabic_en:\n\u001b[0;32m----> 3\u001b[0m     arabic_predictions\u001b[38;5;241m.\u001b[39mappend(predict_category(data))\n\u001b[1;32m      4\u001b[0m     arabic_prediction_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m: arabic_en,\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: arabic_predictions,\n\u001b[1;32m      7\u001b[0m     })\n\u001b[1;32m      8\u001b[0m prediction_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_prediction.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[43], line 6\u001b[0m, in \u001b[0;36mpredict_category\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_category\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     predict_input \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(text,\n\u001b[1;32m      3\u001b[0m     truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(predict_input)\n\u001b[1;32m      7\u001b[0m     prediction_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39margmax(output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction_value\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:977\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    975\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 977\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m    978\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    979\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    980\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    981\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    982\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    983\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    984\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    985\u001b[0m )\n\u001b[1;32m    986\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    987\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:771\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[1;32m    772\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/modeling_utils.py:5153\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   5150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   5152\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[0;32m-> 5153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m input_ids[:, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m   5154\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   5155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5158\u001b[0m     )\n\u001b[1;32m   5160\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[1;32m   5161\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "arabic_predictions = []\n",
    "for data in arabic_en:\n",
    "    arabic_predictions.append(predict_category(data))\n",
    "    arabic_prediction_df = pd.DataFrame({\n",
    "        \"english\": arabic_en,\n",
    "        \"labels\": arabic_predictions,\n",
    "    })\n",
    "prediction_df.to_csv(\"model_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## german"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_list = german[‘english’].to_list()\n",
    "len(korean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean_list = korean[‘english’].to_list()\n",
    "len(korean_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# practice code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14064/ipykernel_76594/40129132.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='848' max='848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [848/848 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 1 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]],\nInput references: [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 1. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#torch.mps.empty_cache()\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#trainer.train()\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(shortened_tokenized_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#short_results = []\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#for item in shortened_tokenized_data['test']:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#result = trainer.evaluate(item)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#print(result)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#short_results.append(result)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(short_results, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tuned DistilBERT\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   4106\u001b[0m     eval_dataloader,\n\u001b[1;32m   4107\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4108\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   4110\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4111\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   4112\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   4113\u001b[0m )\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4394\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4392\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4393\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4394\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   4395\u001b[0m         EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_set_kwargs)\n\u001b[1;32m   4396\u001b[0m     )\n\u001b[1;32m   4397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4398\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m     11\u001b[0m probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(torch\u001b[38;5;241m.\u001b[39mtensor(logits))\n\u001b[1;32m     12\u001b[0m preds \u001b[38;5;241m=\u001b[39m (probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/evaluate/module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_batch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/evaluate/module.py:546\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions and/or references don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the expected format.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput references: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(references)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m     )\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 1 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]],\nInput references: [[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]\n [0. 0. 0. ... 1. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 1. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=shortened_tokenized_data[\"train\"],\n",
    "    eval_dataset=shortened_tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "#torch.mps.empty_cache()\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "#result = trainer.evaluate(shortened_tokenized_data['test'])\n",
    "#short_results = []\n",
    "#for item in shortened_tokenized_data['test']:\n",
    "    #result = trainer.evaluate(item)\n",
    "    #print(result)\n",
    "    #short_results.append(result)\n",
    "    \n",
    "pd.DataFrame(short_results, index=['Fine-tuned DistilBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m shortened_berkeley \u001b[38;5;241m=\u001b[39m berkeley_compressed\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m shortened_berkeley[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m shortened_berkeley[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m      3\u001b[0m shortened_berkeley \u001b[38;5;241m=\u001b[39m shortened_berkeley[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages/pandas/core/series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4759\u001b[0m         func,\n\u001b[1;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages/pandas/core/apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages/pandas/core/apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1291\u001b[0m )\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m shortened_berkeley \u001b[38;5;241m=\u001b[39m berkeley_compressed\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m shortened_berkeley[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m shortened_berkeley[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m      3\u001b[0m shortened_berkeley \u001b[38;5;241m=\u001b[39m shortened_berkeley[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "shortened_berkeley = berkeley_compressed.head(100)\n",
    "shortened_berkeley[\"labels\"] = shortened_berkeley[\"labels\"].apply(lambda x: np.array(x, dtype=np.int64))\n",
    "shortened_berkeley = shortened_berkeley[[\"text\", \"labels\"]]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "features = Features({\n",
    "    \"text\": Value(\"string\"),\n",
    "    \"labels\": Sequence(Value(\"float32\"))  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_short = Dataset.from_pandas(shortened_berkeley, features=features).train_test_split(test_size=0.1)\n",
    "tokenizer_short = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    tokenized = tokenizer_short(examples[\"text\"], truncation=True, padding=True) \n",
    "\n",
    "    labels = examples[\"labels\"]\n",
    "    labels = np.array(labels).astype(np.float32)\n",
    "    \n",
    "    tokenized[\"labels\"] = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c817542496490e8b6ad1f0203e42cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbced0fe37ab417daa02126032d032e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data_short = train_test_short.map(preprocess, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Question: These 4 broads who criticize America, what country did they flee to get here? And now they want to make OUR America like THEIR former HELL HOLE. I don't think so!!!!!!!!!!  Let them explain their GRATITUDE for letting them in OUR country.\", 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 'input_ids': [101, 3160, 1024, 2122, 1018, 5041, 2015, 2040, 6232, 4697, 2637, 1010, 2054, 2406, 2106, 2027, 10574, 2000, 2131, 2182, 1029, 1998, 2085, 2027, 2215, 2000, 2191, 2256, 2637, 2066, 2037, 2280, 3109, 4920, 1012, 1045, 2123, 1005, 1056, 2228, 2061, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 2292, 2068, 4863, 2037, 15531, 2005, 5599, 2068, 1999, 2256, 2406, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data_short[\"train\"][0])\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=20,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_short = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    logits = torch.tensor(logits, dtype=torch.float).cpu()  \n",
    "    labels = torch.tensor(labels, dtype=torch.float).cpu()\n",
    "\n",
    "    probs = torch.sigmoid(torch.tensor(logits))\n",
    "    preds = (probs > 0.5).int().numpy()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "  \n",
    "    return {\n",
    "        \"f1_micro\": f1.compute(predictions=preds, references=labels, average=\"micro\")[\"f1\"],\n",
    "        \"precision_micro\": precision.compute(predictions=preds, references=labels, average=\"micro\")[\"precision\"],\n",
    "        \"recall_micro\": recall.compute(predictions=preds, references=labels, average=\"micro\")[\"recall\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14062/ipykernel_78845/2188472962.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer_short = Trainer(\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]), 'input_ids': tensor([[ 101, 9122, 3393,  ...,    0,    0,    0],\n",
      "        [ 101, 2138, 2009,  ...,    0,    0,    0],\n",
      "        [ 101, 9252, 2465,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4067, 2017,  ...,    0,    0,    0],\n",
      "        [ 101, 6616, 3398,  ...,    0,    0,    0],\n",
      "        [ 101, 1000, 2073,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.448916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.4757084051767985, metrics={'train_runtime': 20.6264, 'train_samples_per_second': 4.363, 'train_steps_per_second': 0.291, 'total_flos': 2585496315600.0, 'train_loss': 0.4757084051767985, 'epoch': 1.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hatespeech_classifier\",\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "trainer_short = Trainer(\n",
    "    model=model_short,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data_short[\"train\"],\n",
    "    eval_dataset=tokenized_data_short[\"test\"],\n",
    "    tokenizer=tokenizer_short,\n",
    "    data_collator=data_collator,\n",
    "    #compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "for batch in trainer_short.get_train_dataloader():\n",
    "    print(batch)\n",
    "    break\n",
    "trainer_short.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]), 'input_ids': tensor([[ 101, 9122, 3393,  ...,    0,    0,    0],\n",
      "        [ 101, 2138, 2009,  ...,    0,    0,    0],\n",
      "        [ 101, 9252, 2465,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 4067, 2017,  ...,    0,    0,    0],\n",
      "        [ 101, 6616, 3398,  ...,    0,    0,    0],\n",
      "        [ 101, 1000, 2073,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.411055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=0.43312708536783856, metrics={'train_runtime': 21.1811, 'train_samples_per_second': 4.249, 'train_steps_per_second': 0.283, 'total_flos': 2585496315600.0, 'train_loss': 0.43312708536783856, 'epoch': 1.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in trainer_short.get_train_dataloader():\n",
    "    print(batch)\n",
    "    break\n",
    "trainer_short.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy is the proportion of correct predictions among the total number of cases processed. It can be computed with:\\nAccuracy = (TP + TN) / (TP + TN + FP + FN)\\n Where:\\nTP: True positive\\nTN: True negative\\nFP: False positive\\nFN: False negative\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for model_inputs, gold_standards in evaluation_dataset:\n",
    " #   predictions = model(model_inputs)\n",
    "#  metric.add_batch(references=gold_standards, predictions=predictions)\n",
    "#metric.compute()\n",
    "\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "#accuracy.description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm-14062/ipykernel_78845/1874909447.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs = torch.sigmoid(torch.tensor(logits))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]],\nInput references: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer_short\u001b[38;5;241m.\u001b[39mevaluate(tokenized_data_short[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFine-tuned DistilBERT\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[38;5;241m=\u001b[39m eval_loop(\n\u001b[1;32m   4106\u001b[0m     eval_dataloader,\n\u001b[1;32m   4107\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4108\u001b[0m     \u001b[38;5;66;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;00m\n\u001b[1;32m   4109\u001b[0m     \u001b[38;5;66;03m# self.args.prediction_loss_only\u001b[39;00m\n\u001b[1;32m   4110\u001b[0m     prediction_loss_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4111\u001b[0m     ignore_keys\u001b[38;5;241m=\u001b[39mignore_keys,\n\u001b[1;32m   4112\u001b[0m     metric_key_prefix\u001b[38;5;241m=\u001b[39mmetric_key_prefix,\n\u001b[1;32m   4113\u001b[0m )\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4394\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4392\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4393\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4394\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   4395\u001b[0m         EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meval_set_kwargs)\n\u001b[1;32m   4396\u001b[0m     )\n\u001b[1;32m   4397\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4398\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[23], line 12\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m (probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall_micro\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpreds, references\u001b[38;5;241m=\u001b[39mlabels, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/evaluate/module.py:455\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_batch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/evaluate/module.py:546\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions and/or references don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the expected format.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput references: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummarize_if_long_list(references)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m     )\n\u001b[0;32m--> 546\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)},\nInput predictions: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]],\nInput references: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]]"
     ]
    }
   ],
   "source": [
    "#for model_inputs, gold_standards in evaluation_dataset:\n",
    " #   predictions = model(model_inputs)\n",
    "#  metric.add_batch(references=gold_standards, predictions=predictions)\n",
    "#metric.compute()\n",
    "\n",
    "\n",
    "accuracy = evaluate.load('accuracy')\n",
    "\n",
    "\n",
    "results = trainer_short.evaluate(tokenized_data_short['test'])\n",
    "pd.DataFrame(results, index=['Fine-tuned DistilBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
