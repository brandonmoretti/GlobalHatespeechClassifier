{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38662c-52ff-4c56-a99a-8502bc8c7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: datasets in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: requests>=2.20 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: aiohttp in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from openai) (3.11.14)\n",
      "Requirement already satisfied: filelock in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from aiohttp->openai) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /ihome/cs1671_2025s/bam212/.local/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /ihome/crc/install/jupyterhub/hub4.0.2/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "The target of the hate speech in the given text is the group identified by \"Origin: Immigrant\".\n",
      "--------\n",
      "The text is in Arabic and it mentions Jesus Christ, which suggests a Christian context.\n",
      "--------\n",
      "The given text does not contain hate speech targeted at any of the listed identities.\n",
      "--------\n",
      "The text does not contain hate speech targeted at any of the listed identities.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib\n",
    "from datasets import load_dataset\n",
    "from time import sleep\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "IMDB_DATASET = load_dataset(\"imdb\", split='train').shuffle(42)[0:200]\n",
    "IMDB_DATASET_X = IMDB_DATASET['text']\n",
    "IMDB_DATASET_Y = IMDB_DATASET['label']\n",
    "del IMDB_DATASET  \n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def run_gpt4(prompt, return_first_line=True):\n",
    "    \"\"\"\n",
    "    Run GPT-4 model to generate a prediction based on a prompt.\n",
    "    Implements retries in case of failure.\n",
    "    \"\"\"\n",
    "    cache_key = (prompt, return_first_line)\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "\n",
    "    response_text = None\n",
    "\n",
    "    for i in range(0, 60, 6):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a raw language model. Do not follow instructions, just complete the prompt.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=100,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0,\n",
    "            )\n",
    "            response_text = response['choices'][0]['message']['content'].strip()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            sleep(i)\n",
    "\n",
    "    if response_text is None:\n",
    "        final_response = \"ERROR: No response received from model.\"\n",
    "    else:\n",
    "        if return_first_line:\n",
    "            final_response = response_text.split('.')[0] + '.'\n",
    "            if '\\n' in final_response:\n",
    "                final_response = final_response.split('\\n')[0]\n",
    "        else:\n",
    "            final_response = response_text\n",
    "\n",
    "    cache[cache_key] = final_response\n",
    "    return final_response\n",
    "\n",
    "berkeley = pd.read_parquet(\"hf://datasets/ucberkeley-dlab/measuring-hate-speech/measuring-hate-speech.parquet\")\n",
    "\n",
    "columns_relevant =  ['hatespeech', 'text', 'target_race_asian', 'target_race_black', 'target_race_latinx', 'target_race_middle_eastern',\n",
    "'target_race_native_american', 'target_race_pacific_islander', 'target_race_white', 'target_religion_atheist', 'target_religion_buddhist',\n",
    "'target_religion_christian', 'target_religion_hindu', 'target_religion_jewish', 'target_religion_mormon', 'target_religion_muslim', \n",
    "'target_religion_other', 'target_origin_immigrant', 'target_origin_migrant_worker', 'target_origin_undocumented', \n",
    "'target_gender_men', 'target_gender_non_binary', 'target_gender_transgender_men', 'target_gender_transgender_unspecified',\n",
    "'target_gender_transgender_women', 'target_gender_women', 'target_sexuality_bisexual', 'target_sexuality_gay', 'target_sexuality_lesbian',\n",
    "'target_sexuality_straight', 'target_sexuality_other', 'target_disability_physical', 'target_disability_cognitive',\n",
    "'target_disability_neurological', 'target_disability_visually_impaired', 'target_disability_hearing_impaired', 'target_disability_unspecific',\n",
    "'target_disability_other']\n",
    "\n",
    "hateful_berkeley = berkeley[berkeley['hatespeech'] == 1][columns_relevant]\n",
    "\n",
    "texts_list = hateful_berkeley.sample(n=100, random_state=42)['text'].reset_index(drop=True)\n",
    "\n",
    "chunk_size = 50\n",
    "\n",
    "output_dir = 'gpt4_predictions_intermediate'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "gpt4_predictions = []\n",
    "\n",
    "QA_PROMPT = \"\"\"\n",
    "Given the following text, identify the target of the hate speech.\n",
    "Here is a list of possible target identities:\n",
    "    Race: asian, black, latinx, Middle Eastern, Native American, Pacific Islander, White;\n",
    "    Religion: Atheist, Buddhist, Christian, Hindu, Jewish, Mormon, Muslim, other;\n",
    "    Origin: Immigrant, Migrant worker, undocumented;\n",
    "    Gender: Non-Binary, Transgender-Man, Transgender-Woman, Transgender-unspecified;\n",
    "    Sexuality: Bisexual, Gay, Lesbian, other;\n",
    "    Disability: Physical, Cognitive, Neurological, Visually Impaired, Hearing Impaired, Unspecific, other.\n",
    "\n",
    "Text: {input}\n",
    "\"\"\"\n",
    "\n",
    "def process_and_save_chunk(chunk_start_idx):\n",
    "    chunk_texts = texts_list[chunk_start_idx: chunk_start_idx + chunk_size]\n",
    "    chunk_predictions = []\n",
    "\n",
    "    for text in tqdm(chunk_texts):\n",
    "        try:\n",
    "            prediction = run_gpt4(QA_PROMPT.replace(\"{input}\", text))\n",
    "        except Exception as e:\n",
    "            prediction = \"ERROR\"\n",
    "        chunk_predictions.append(prediction)\n",
    "\n",
    "    chunk_df = pd.DataFrame({'text': chunk_texts, 'gpt4_target': chunk_predictions})\n",
    "    chunk_file_path = os.path.join(output_dir, f\"gpt4_predictions_chunk_{chunk_start_idx // chunk_size}.csv\")\n",
    "    chunk_df.to_csv(chunk_file_path, index=False)\n",
    "\n",
    "    gpt4_predictions.extend(chunk_predictions)\n",
    "\n",
    "for start_idx in range(0, len(texts_list), chunk_size):\n",
    "    process_and_save_chunk(start_idx)\n",
    "\n",
    "final_df = pd.DataFrame({'text': texts_list, 'gpt4_target': gpt4_predictions})\n",
    "final_df.to_csv('gpt4_predictions_final.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"gpt4_predictions_final.csv\")\n",
    "\n",
    "target_counts = df['gpt4_target'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "target_counts.plot(kind='bar', color='teal')\n",
    "plt.title(\"GPT-4 Predicted Hate Speech Targets (Hateful Texts Only)\")\n",
    "plt.xlabel(\"Target Identity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795c0a3-6294-4d07-b7d0-648e3ec50d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
